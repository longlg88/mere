#!/usr/bin/env python3
"""
ë°ì´í„° ë™ê¸°í™” í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
Day 11: Offline Mode & Data Sync Testing
"""

import asyncio
import json
import time
import argparse
from typing import Dict, List, Any, Optional

class DataSyncTest:
    def __init__(self, scenario: str = "full"):
        self.test_results = []
        self.start_time = time.time()
        self.scenario = scenario
        
        # Mock data stores
        self.local_store = {}
        self.server_store = {}
        self.sync_queue = []
    
    async def run_sync_tests(self):
        """ë™ê¸°í™” í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print(f"ğŸ”„ ë°ì´í„° ë™ê¸°í™” í…ŒìŠ¤íŠ¸ ì‹œì‘ (ì‹œë‚˜ë¦¬ì˜¤: {self.scenario})")
        print("=" * 60)
        
        if self.scenario == "full":
            tests = [
                self.test_basic_sync,
                self.test_bidirectional_sync,
                self.test_conflict_resolution,
                self.test_incremental_sync,
                self.test_batch_sync,
                self.test_sync_failure_recovery,
                self.test_partial_sync,
                self.test_sync_performance
            ]
        elif self.scenario == "conflict_resolution":
            tests = [
                self.test_conflict_resolution,
                self.test_complex_conflicts,
                self.test_concurrent_modifications
            ]
        elif self.scenario == "performance":
            tests = [
                self.test_sync_performance,
                self.test_large_dataset_sync,
                self.test_sync_under_load
            ]
        else:
            tests = [self.test_basic_sync]
        
        passed = 0
        failed = 0
        
        for test_func in tests:
            try:
                result = await test_func()
                if result:
                    passed += 1
                    print(f"âœ… {test_func.__name__}: PASS")
                else:
                    failed += 1
                    print(f"âŒ {test_func.__name__}: FAIL")
                    
                self.test_results.append({
                    "test": test_func.__name__,
                    "status": "PASS" if result else "FAIL",
                    "timestamp": time.time() - self.start_time
                })
                
            except Exception as e:
                failed += 1
                print(f"âŒ {test_func.__name__}: ERROR - {e}")
                self.test_results.append({
                    "test": test_func.__name__,
                    "status": "ERROR",
                    "error": str(e),
                    "timestamp": time.time() - self.start_time
                })
        
        # Summary
        print("\n" + "=" * 60)
        print(f"ğŸ¯ ë™ê¸°í™” í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print(f"   í†µê³¼: {passed}")
        print(f"   ì‹¤íŒ¨: {failed}")
        print(f"   ì´ í…ŒìŠ¤íŠ¸: {passed + failed}")
        print(f"   ì„±ê³µë¥ : {(passed / (passed + failed) * 100):.1f}%")
        print(f"   ì‹¤í–‰ ì‹œê°„: {time.time() - self.start_time:.2f}ì´ˆ")
        
        return passed, failed
    
    async def test_basic_sync(self) -> bool:
        """ê¸°ë³¸ ë™ê¸°í™” í…ŒìŠ¤íŠ¸"""
        print("\nğŸ”„ í…ŒìŠ¤íŠ¸: ê¸°ë³¸ ë™ê¸°í™”")
        
        # Setup initial data
        local_items = [
            {"id": "memo_1", "type": "memo", "content": "ë¡œì»¬ ë©”ëª¨ 1", "synced": False},
            {"id": "todo_1", "type": "todo", "title": "ë¡œì»¬ í• ì¼ 1", "synced": False},
            {"id": "event_1", "type": "event", "title": "ë¡œì»¬ ì´ë²¤íŠ¸ 1", "synced": False}
        ]
        
        self.local_store = {item["id"]: item for item in local_items}
        self.server_store = {}
        
        print(f"   ğŸ“‹ ë¡œì»¬ í•­ëª©: {len(local_items)}ê°œ")
        
        # Perform sync
        sync_result = await self.simulate_basic_sync()
        
        # Verify results
        synced_items = sum(1 for item in self.local_store.values() if item.get("synced", False))
        server_items = len(self.server_store)
        
        print(f"   ğŸ“¤ ë™ê¸°í™”ëœ í•­ëª©: {synced_items}ê°œ")
        print(f"   ğŸŒ ì„œë²„ í•­ëª©: {server_items}ê°œ")
        
        success = synced_items == len(local_items) and server_items == len(local_items)
        print(f"   ğŸ“Š ê¸°ë³¸ ë™ê¸°í™” ì„±ê³µ: {success}")
        
        return success
    
    async def test_bidirectional_sync(self) -> bool:
        """ì–‘ë°©í–¥ ë™ê¸°í™” í…ŒìŠ¤íŠ¸"""
        print("\nâ†”ï¸  í…ŒìŠ¤íŠ¸: ì–‘ë°©í–¥ ë™ê¸°í™”")
        
        # Setup data on both sides
        local_items = [
            {"id": "memo_1", "type": "memo", "content": "ë¡œì»¬ë§Œ ë©”ëª¨", "synced": False, "created_at": "2024-01-01T10:00:00"},
            {"id": "shared_1", "type": "memo", "content": "ë¡œì»¬ ë²„ì „", "synced": True, "updated_at": "2024-01-01T11:00:00"}
        ]
        
        server_items = [
            {"id": "memo_2", "type": "memo", "content": "ì„œë²„ë§Œ ë©”ëª¨", "created_at": "2024-01-01T09:00:00"},
            {"id": "shared_1", "type": "memo", "content": "ì„œë²„ ë²„ì „", "updated_at": "2024-01-01T10:30:00"}
        ]
        
        self.local_store = {item["id"]: item for item in local_items}
        self.server_store = {item["id"]: item for item in server_items}
        
        print(f"   ğŸ“± ë¡œì»¬ í•­ëª©: {len(local_items)}ê°œ")
        print(f"   ğŸŒ ì„œë²„ í•­ëª©: {len(server_items)}ê°œ")
        
        # Perform bidirectional sync
        sync_result = await self.simulate_bidirectional_sync()
        
        # Verify results
        final_local_count = len(self.local_store)
        final_server_count = len(self.server_store)
        
        # Should have: memo_1 (local), memo_2 (from server), shared_1 (resolved)
        expected_items = 3
        
        print(f"   ğŸ“± ìµœì¢… ë¡œì»¬: {final_local_count}ê°œ")
        print(f"   ğŸŒ ìµœì¢… ì„œë²„: {final_server_count}ê°œ")
        
        success = final_local_count == expected_items and final_server_count == expected_items
        print(f"   ğŸ“Š ì–‘ë°©í–¥ ë™ê¸°í™” ì„±ê³µ: {success}")
        
        return success
    
    async def test_conflict_resolution(self) -> bool:
        """ì¶©ëŒ í•´ê²° í…ŒìŠ¤íŠ¸"""
        print("\nâš”ï¸  í…ŒìŠ¤íŠ¸: ì¶©ëŒ í•´ê²°")
        
        # Create conflicting items
        conflicts = [
            {
                "id": "conflict_1",
                "local": {"content": "ë¡œì»¬ ìˆ˜ì •", "updated_at": "2024-01-01T12:00:00"},
                "server": {"content": "ì„œë²„ ìˆ˜ì •", "updated_at": "2024-01-01T11:30:00"}
            },
            {
                "id": "conflict_2", 
                "local": {"title": "ë¡œì»¬ ì œëª©", "updated_at": "2024-01-01T10:00:00"},
                "server": {"title": "ì„œë²„ ì œëª©", "updated_at": "2024-01-01T10:30:00"}
            }
        ]
        
        resolved_conflicts = 0
        
        for conflict in conflicts:
            await asyncio.sleep(0.1)
            
            resolution = await self.simulate_conflict_resolution(conflict)
            
            if resolution["resolved"]:
                resolved_conflicts += 1
                print(f"   âœ… ì¶©ëŒ í•´ê²°: {conflict['id']} -> {resolution['strategy']}")
            else:
                print(f"   âŒ ì¶©ëŒ í•´ê²° ì‹¤íŒ¨: {conflict['id']}")
        
        resolution_rate = resolved_conflicts / len(conflicts)
        print(f"   ğŸ“Š ì¶©ëŒ í•´ê²°ë¥ : {resolution_rate * 100:.1f}% ({resolved_conflicts}/{len(conflicts)})")
        
        return resolution_rate >= 1.0
    
    async def test_incremental_sync(self) -> bool:
        """ì¦ë¶„ ë™ê¸°í™” í…ŒìŠ¤íŠ¸"""
        print("\nğŸ“ˆ í…ŒìŠ¤íŠ¸: ì¦ë¶„ ë™ê¸°í™”")
        
        # Setup initial synced state
        base_items = [
            {"id": "memo_1", "type": "memo", "content": "ê¸°ì¡´ ë©”ëª¨", "synced": True, "version": 1},
            {"id": "todo_1", "type": "todo", "title": "ê¸°ì¡´ í• ì¼", "synced": True, "version": 1}
        ]
        
        # Add new items (incremental changes)
        new_items = [
            {"id": "memo_2", "type": "memo", "content": "ìƒˆ ë©”ëª¨", "synced": False, "version": 1},
            {"id": "memo_1", "type": "memo", "content": "ìˆ˜ì •ëœ ë©”ëª¨", "synced": False, "version": 2}  # Updated
        ]
        
        self.local_store = {item["id"]: item for item in base_items}
        self.local_store.update({item["id"]: item for item in new_items})
        
        # Simulate incremental sync
        changes_detected = await self.detect_incremental_changes()
        sync_result = await self.simulate_incremental_sync(changes_detected)
        
        # Verify only changed items were synced
        sync_operations = sync_result["operations"]
        expected_changes = 2  # memo_2 (new), memo_1 (updated)
        
        print(f"   ğŸ” ê°ì§€ëœ ë³€ê²½ì‚¬í•­: {len(changes_detected)}ê°œ")
        print(f"   ğŸ”„ ë™ê¸°í™” ì‘ì—…: {len(sync_operations)}ê°œ")
        
        success = len(changes_detected) == expected_changes and len(sync_operations) == expected_changes
        print(f"   ğŸ“Š ì¦ë¶„ ë™ê¸°í™” ì„±ê³µ: {success}")
        
        return success
    
    async def test_batch_sync(self) -> bool:
        """ë°°ì¹˜ ë™ê¸°í™” í…ŒìŠ¤íŠ¸"""
        print("\nğŸ“¦ í…ŒìŠ¤íŠ¸: ë°°ì¹˜ ë™ê¸°í™”")
        
        # Create large number of items
        batch_size = 50
        items = []
        
        for i in range(batch_size):
            items.append({
                "id": f"item_{i}",
                "type": "memo",
                "content": f"ë°°ì¹˜ í•­ëª© {i}",
                "synced": False
            })
        
        self.local_store = {item["id"]: item for item in items}
        
        print(f"   ğŸ“‹ ë°°ì¹˜ í•­ëª©: {len(items)}ê°œ")
        
        # Perform batch sync
        start_time = time.time()
        sync_result = await self.simulate_batch_sync(batch_size=10)
        sync_time = time.time() - start_time
        
        # Verify results
        synced_items = sum(1 for item in self.local_store.values() if item.get("synced", False))
        batch_operations = sync_result["batches"]
        
        print(f"   ğŸ”„ ë°°ì¹˜ ìˆ˜: {batch_operations}ê°œ")
        print(f"   ğŸ“¤ ë™ê¸°í™”ëœ í•­ëª©: {synced_items}ê°œ")
        print(f"   â±ï¸  ë™ê¸°í™” ì‹œê°„: {sync_time:.2f}ì´ˆ")
        
        success = synced_items == len(items) and sync_time < 5.0  # Should complete in 5 seconds
        print(f"   ğŸ“Š ë°°ì¹˜ ë™ê¸°í™” ì„±ê³µ: {success}")
        
        return success
    
    async def test_sync_failure_recovery(self) -> bool:
        """ë™ê¸°í™” ì‹¤íŒ¨ ë³µêµ¬ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ”§ í…ŒìŠ¤íŠ¸: ë™ê¸°í™” ì‹¤íŒ¨ ë³µêµ¬")
        
        # Setup items for sync
        items = [
            {"id": "memo_1", "type": "memo", "content": "ì„±ê³µ ì˜ˆì •", "synced": False},
            {"id": "memo_2", "type": "memo", "content": "ì‹¤íŒ¨ ì˜ˆì •", "synced": False},
            {"id": "memo_3", "type": "memo", "content": "ì¬ì‹œë„ ì„±ê³µ", "synced": False}
        ]
        
        self.local_store = {item["id"]: item for item in items}
        
        # Simulate sync with failures
        failed_items = ["memo_2"]
        retry_items = ["memo_3"]
        
        sync_result = await self.simulate_sync_with_failures(failed_items, retry_items)
        
        # Verify recovery
        successful_syncs = sync_result["successful"]
        failed_syncs = sync_result["failed"]
        retried_syncs = sync_result["retried"]
        
        print(f"   âœ… ì„±ê³µ: {successful_syncs}ê°œ")
        print(f"   âŒ ì‹¤íŒ¨: {failed_syncs}ê°œ")
        print(f"   ğŸ”„ ì¬ì‹œë„ ì„±ê³µ: {retried_syncs}ê°œ")
        
        # Should have 2 successful (memo_1 + retried memo_3), 1 failed (memo_2)
        expected_success = 2
        expected_failed = 1
        
        success = successful_syncs == expected_success and failed_syncs == expected_failed
        print(f"   ğŸ“Š ì‹¤íŒ¨ ë³µêµ¬ ì„±ê³µ: {success}")
        
        return success
    
    async def test_partial_sync(self) -> bool:
        """ë¶€ë¶„ ë™ê¸°í™” í…ŒìŠ¤íŠ¸"""
        print("\nğŸ¯ í…ŒìŠ¤íŠ¸: ë¶€ë¶„ ë™ê¸°í™”")
        
        # Setup items with different priorities
        items = [
            {"id": "urgent_1", "type": "todo", "priority": "high", "synced": False},
            {"id": "normal_1", "type": "memo", "priority": "normal", "synced": False},
            {"id": "urgent_2", "type": "event", "priority": "high", "synced": False},
            {"id": "low_1", "type": "memo", "priority": "low", "synced": False}
        ]
        
        self.local_store = {item["id"]: item for item in items}
        
        # Sync only high priority items first
        high_priority_sync = await self.simulate_priority_sync("high")
        
        # Then sync remaining items
        remaining_sync = await self.simulate_priority_sync("normal")
        
        # Verify results
        high_priority_synced = high_priority_sync["synced_count"]
        total_synced = high_priority_synced + remaining_sync["synced_count"]
        
        print(f"   ğŸ”¥ ê³ ìš°ì„ ìˆœìœ„ ë™ê¸°í™”: {high_priority_synced}ê°œ")
        print(f"   ğŸ“‹ ì´ ë™ê¸°í™”: {total_synced}ê°œ")
        
        expected_high_priority = 2  # urgent_1, urgent_2
        expected_total = 3  # All except low priority for this test
        
        success = high_priority_synced == expected_high_priority and total_synced >= expected_total
        print(f"   ğŸ“Š ë¶€ë¶„ ë™ê¸°í™” ì„±ê³µ: {success}")
        
        return success
    
    async def test_sync_performance(self) -> bool:
        """ë™ê¸°í™” ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print("\nâš¡ í…ŒìŠ¤íŠ¸: ë™ê¸°í™” ì„±ëŠ¥")
        
        # Test different data sizes
        test_sizes = [10, 50, 100]
        performance_results = []
        
        for size in test_sizes:
            # Create test data
            items = [
                {"id": f"perf_{i}", "type": "memo", "content": f"ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ {i}", "synced": False}
                for i in range(size)
            ]
            
            self.local_store = {item["id"]: item for item in items}
            
            # Measure sync time
            start_time = time.time()
            await self.simulate_performance_sync()
            sync_time = time.time() - start_time
            
            throughput = size / sync_time if sync_time > 0 else float('inf')
            performance_results.append({"size": size, "time": sync_time, "throughput": throughput})
            
            print(f"   ğŸ“Š {size}ê°œ í•­ëª©: {sync_time:.2f}ì´ˆ ({throughput:.1f} items/sec)")
        
        # Check performance criteria
        # Should handle 100 items in under 10 seconds
        large_test = performance_results[-1]
        performance_ok = large_test["time"] < 10.0 and large_test["throughput"] > 10
        
        print(f"   ğŸ“Š ì„±ëŠ¥ ê¸°ì¤€ ë‹¬ì„±: {performance_ok}")
        
        return performance_ok
    
    async def test_complex_conflicts(self) -> bool:
        """ë³µì¡í•œ ì¶©ëŒ í…ŒìŠ¤íŠ¸"""
        print("\nğŸŒªï¸  í…ŒìŠ¤íŠ¸: ë³µì¡í•œ ì¶©ëŒ")
        
        # Multi-field conflicts
        complex_conflicts = [
            {
                "id": "complex_1",
                "local": {
                    "title": "ë¡œì»¬ ì œëª©",
                    "content": "ë¡œì»¬ ë‚´ìš©", 
                    "priority": "high",
                    "updated_at": "2024-01-01T12:00:00"
                },
                "server": {
                    "title": "ì„œë²„ ì œëª©",
                    "content": "ë¡œì»¬ ë‚´ìš©",  # Same content
                    "priority": "low",
                    "updated_at": "2024-01-01T11:30:00"
                }
            }
        ]
        
        resolution_strategies = []
        
        for conflict in complex_conflicts:
            resolution = await self.simulate_complex_conflict_resolution(conflict)
            resolution_strategies.append(resolution)
            
            print(f"   ğŸ” í•„ë“œë³„ ì¶©ëŒ í•´ê²°:")
            for field, strategy in resolution["field_resolutions"].items():
                print(f"     - {field}: {strategy}")
        
        # All conflicts should be resolved
        success = all(r["resolved"] for r in resolution_strategies)
        print(f"   ğŸ“Š ë³µì¡í•œ ì¶©ëŒ í•´ê²°: {success}")
        
        return success
    
    async def test_concurrent_modifications(self) -> bool:
        """ë™ì‹œ ìˆ˜ì • í…ŒìŠ¤íŠ¸"""
        print("\nğŸ”€ í…ŒìŠ¤íŠ¸: ë™ì‹œ ìˆ˜ì •")
        
        # Simulate concurrent modifications
        base_item = {"id": "concurrent_1", "content": "ì›ë³¸ ë‚´ìš©", "version": 1}
        
        # Multiple simultaneous modifications
        modifications = [
            {"user": "user_a", "content": "ì‚¬ìš©ì A ìˆ˜ì •", "timestamp": "2024-01-01T12:00:00"},
            {"user": "user_b", "content": "ì‚¬ìš©ì B ìˆ˜ì •", "timestamp": "2024-01-01T12:00:01"},
            {"user": "user_c", "content": "ì‚¬ìš©ì C ìˆ˜ì •", "timestamp": "2024-01-01T12:00:02"}
        ]
        
        # Process concurrent modifications
        result = await self.simulate_concurrent_modifications(base_item, modifications)
        
        # Should handle conflicts and determine final state
        final_state = result["final_state"]
        conflict_count = result["conflicts_resolved"]
        
        print(f"   ğŸ”„ ë™ì‹œ ìˆ˜ì • ì²˜ë¦¬: {len(modifications)}ê°œ")
        print(f"   âš”ï¸  í•´ê²°ëœ ì¶©ëŒ: {conflict_count}ê°œ")
        print(f"   âœ… ìµœì¢… ìƒíƒœ: {final_state['user']} ë²„ì „ ì ìš©")
        
        success = final_state is not None and conflict_count == len(modifications) - 1
        print(f"   ğŸ“Š ë™ì‹œ ìˆ˜ì • ì²˜ë¦¬ ì„±ê³µ: {success}")
        
        return success
    
    async def test_large_dataset_sync(self) -> bool:
        """ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ë™ê¸°í™” í…ŒìŠ¤íŠ¸"""
        print("\nğŸ—ƒï¸  í…ŒìŠ¤íŠ¸: ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ë™ê¸°í™”")
        
        # Create large dataset
        large_dataset_size = 1000
        items = []
        
        for i in range(large_dataset_size):
            items.append({
                "id": f"large_{i}",
                "type": "memo",
                "content": f"ëŒ€ìš©ëŸ‰ ë°ì´í„° {i}" * 10,  # Larger content
                "synced": False
            })
        
        self.local_store = {item["id"]: item for item in items}
        
        print(f"   ğŸ“Š ë°ì´í„°ì…‹ í¬ê¸°: {large_dataset_size}ê°œ")
        
        # Measure sync performance
        start_time = time.time()
        result = await self.simulate_large_dataset_sync()
        sync_time = time.time() - start_time
        
        throughput = large_dataset_size / sync_time if sync_time > 0 else 0
        memory_usage = result.get("memory_mb", 0)
        
        print(f"   â±ï¸  ë™ê¸°í™” ì‹œê°„: {sync_time:.2f}ì´ˆ")
        print(f"   ğŸ“ˆ ì²˜ë¦¬ìœ¨: {throughput:.1f} items/sec")
        print(f"   ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_usage:.1f}MB")
        
        # Performance criteria for large dataset
        success = sync_time < 30.0 and throughput > 30 and memory_usage < 100
        print(f"   ğŸ“Š ëŒ€ìš©ëŸ‰ ë™ê¸°í™” ì„±ê³µ: {success}")
        
        return success
    
    async def test_sync_under_load(self) -> bool:
        """ë¶€í•˜ ìƒí™©ì—ì„œ ë™ê¸°í™” í…ŒìŠ¤íŠ¸"""
        print("\nğŸ”¥ í…ŒìŠ¤íŠ¸: ë¶€í•˜ ìƒí™© ë™ê¸°í™”")
        
        # Simulate high load conditions
        concurrent_users = 5
        items_per_user = 20
        
        # Create concurrent sync operations
        sync_tasks = []
        
        for user_id in range(concurrent_users):
            user_items = [
                {
                    "id": f"user_{user_id}_item_{i}",
                    "type": "memo",
                    "content": f"ì‚¬ìš©ì {user_id} í•­ëª© {i}",
                    "synced": False
                }
                for i in range(items_per_user)
            ]
            
            sync_tasks.append(self.simulate_user_sync(user_id, user_items))
        
        # Execute concurrent syncs
        start_time = time.time()
        results = await asyncio.gather(*sync_tasks, return_exceptions=True)
        total_time = time.time() - start_time
        
        # Analyze results
        successful_syncs = sum(1 for r in results if isinstance(r, dict) and r.get("success"))
        failed_syncs = len(results) - successful_syncs
        total_items = concurrent_users * items_per_user
        
        print(f"   ğŸ‘¥ ë™ì‹œ ì‚¬ìš©ì: {concurrent_users}ëª…")
        print(f"   ğŸ“‹ ì´ í•­ëª©: {total_items}ê°œ")
        print(f"   âœ… ì„±ê³µí•œ ë™ê¸°í™”: {successful_syncs}ê°œ")
        print(f"   âŒ ì‹¤íŒ¨í•œ ë™ê¸°í™”: {failed_syncs}ê°œ")
        print(f"   â±ï¸  ì´ ì‹œê°„: {total_time:.2f}ì´ˆ")
        
        success_rate = successful_syncs / len(results)
        success = success_rate >= 0.8 and total_time < 20.0  # 80% success rate, under 20 seconds
        
        print(f"   ğŸ“Š ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì„±ê³µë¥ : {success_rate * 100:.1f}%")
        print(f"   ğŸ“Š ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì„±ê³µ: {success}")
        
        return success
    
    # Simulation Methods
    
    async def simulate_basic_sync(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ë™ê¸°í™” ì‹œë®¬ë ˆì´ì…˜"""
        synced_count = 0
        
        for item_id, item in self.local_store.items():
            if not item.get("synced", False):
                await asyncio.sleep(0.05)  # Simulate network delay
                
                # Add to server
                self.server_store[item_id] = item.copy()
                
                # Mark as synced
                item["synced"] = True
                synced_count += 1
        
        return {"synced_count": synced_count}
    
    async def simulate_bidirectional_sync(self) -> Dict[str, Any]:
        """ì–‘ë°©í–¥ ë™ê¸°í™” ì‹œë®¬ë ˆì´ì…˜"""
        # Sync local to server
        for item_id, item in self.local_store.items():
            if not item.get("synced", False):
                self.server_store[item_id] = item.copy()
                item["synced"] = True
        
        # Sync server to local
        for item_id, item in self.server_store.items():
            if item_id not in self.local_store:
                self.local_store[item_id] = item.copy()
            else:
                # Handle conflicts (server version wins for simplicity)
                local_item = self.local_store[item_id]
                if "updated_at" in item and "updated_at" in local_item:
                    if item["updated_at"] > local_item["updated_at"]:
                        self.local_store[item_id] = item.copy()
        
        return {"success": True}
    
    async def simulate_conflict_resolution(self, conflict: Dict[str, Any]) -> Dict[str, Any]:
        """ì¶©ëŒ í•´ê²° ì‹œë®¬ë ˆì´ì…˜"""
        local_time = conflict["local"]["updated_at"]
        server_time = conflict["server"]["updated_at"]
        
        # Latest timestamp wins
        if local_time > server_time:
            chosen = "local"
            strategy = "local_wins"
        else:
            chosen = "server"
            strategy = "server_wins"
        
        return {
            "resolved": True,
            "strategy": strategy,
            "chosen": chosen
        }
    
    async def detect_incremental_changes(self) -> List[Dict[str, Any]]:
        """ì¦ë¶„ ë³€ê²½ì‚¬í•­ ê°ì§€"""
        changes = []
        
        for item_id, item in self.local_store.items():
            if not item.get("synced", False) or item.get("version", 1) > 1:
                changes.append({
                    "id": item_id,
                    "type": "update" if item.get("synced", False) else "create",
                    "item": item
                })
        
        return changes
    
    async def simulate_incremental_sync(self, changes: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ì¦ë¶„ ë™ê¸°í™” ì‹œë®¬ë ˆì´ì…˜"""
        operations = []
        
        for change in changes:
            await asyncio.sleep(0.02)  # Simulate processing
            operations.append({
                "id": change["id"],
                "operation": change["type"],
                "success": True
            })
            
            # Mark as synced
            self.local_store[change["id"]]["synced"] = True
        
        return {"operations": operations}
    
    async def simulate_batch_sync(self, batch_size: int = 10) -> Dict[str, Any]:
        """ë°°ì¹˜ ë™ê¸°í™” ì‹œë®¬ë ˆì´ì…˜"""
        items = list(self.local_store.values())
        batches = [items[i:i + batch_size] for i in range(0, len(items), batch_size)]
        
        for batch in batches:
            await asyncio.sleep(0.2)  # Simulate batch processing
            
            for item in batch:
                item["synced"] = True
        
        return {"batches": len(batches)}
    
    async def simulate_sync_with_failures(self, failed_items: List[str], retry_items: List[str]) -> Dict[str, Any]:
        """ì‹¤íŒ¨ë¥¼ í¬í•¨í•œ ë™ê¸°í™” ì‹œë®¬ë ˆì´ì…˜"""
        successful = 0
        failed = 0
        retried = 0
        
        for item_id, item in self.local_store.items():
            await asyncio.sleep(0.05)
            
            if item_id in failed_items:
                failed += 1
            elif item_id in retry_items:
                # Simulate retry success
                await asyncio.sleep(0.1)
                retried += 1
                item["synced"] = True
            else:
                successful += 1
                item["synced"] = True
        
        return {
            "successful": successful,
            "failed": failed,
            "retried": retried
        }
    
    async def simulate_priority_sync(self, priority: str) -> Dict[str, Any]:
        """ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ë™ê¸°í™” ì‹œë®¬ë ˆì´ì…˜"""
        synced_count = 0
        
        for item_id, item in self.local_store.items():
            if item.get("priority") == priority and not item.get("synced", False):
                await asyncio.sleep(0.03)
                item["synced"] = True
                synced_count += 1
        
        return {"synced_count": synced_count}
    
    async def simulate_performance_sync(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ìš© ë™ê¸°í™” ì‹œë®¬ë ˆì´ì…˜"""
        # Optimized batch processing
        batch_size = 20
        items = list(self.local_store.values())
        
        for i in range(0, len(items), batch_size):
            batch = items[i:i + batch_size]
            await asyncio.sleep(0.1)  # Reduced delay for performance test
            
            for item in batch:
                item["synced"] = True
        
        return {"success": True}
    
    async def simulate_complex_conflict_resolution(self, conflict: Dict[str, Any]) -> Dict[str, Any]:
        """ë³µì¡í•œ ì¶©ëŒ í•´ê²° ì‹œë®¬ë ˆì´ì…˜"""
        local = conflict["local"]
        server = conflict["server"]
        
        field_resolutions = {}
        
        # Resolve each field separately
        for field in set(local.keys()) | set(server.keys()):
            if field in local and field in server:
                if local[field] != server[field]:
                    # Use latest timestamp strategy
                    if local.get("updated_at", "") > server.get("updated_at", ""):
                        field_resolutions[field] = "local_wins"
                    else:
                        field_resolutions[field] = "server_wins"
                else:
                    field_resolutions[field] = "no_conflict"
            elif field in local:
                field_resolutions[field] = "local_only"
            else:
                field_resolutions[field] = "server_only"
        
        return {
            "resolved": True,
            "field_resolutions": field_resolutions
        }
    
    async def simulate_concurrent_modifications(self, base_item: Dict[str, Any], modifications: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ë™ì‹œ ìˆ˜ì • ì‹œë®¬ë ˆì´ì…˜"""
        # Sort by timestamp to determine order
        sorted_mods = sorted(modifications, key=lambda x: x["timestamp"])
        
        # Last modification wins
        final_state = sorted_mods[-1]
        conflicts_resolved = len(modifications) - 1
        
        return {
            "final_state": final_state,
            "conflicts_resolved": conflicts_resolved
        }
    
    async def simulate_large_dataset_sync(self) -> Dict[str, Any]:
        """ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ë™ê¸°í™” ì‹œë®¬ë ˆì´ì…˜"""
        # Simulate memory usage
        import sys
        memory_mb = len(self.local_store) * 0.05  # Rough estimate
        
        # Efficient batch processing
        batch_size = 100
        items = list(self.local_store.values())
        
        for i in range(0, len(items), batch_size):
            batch = items[i:i + batch_size]
            await asyncio.sleep(0.05)  # Minimal delay for large dataset
            
            for item in batch:
                item["synced"] = True
        
        return {"memory_mb": memory_mb}
    
    async def simulate_user_sync(self, user_id: int, items: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ì‚¬ìš©ìë³„ ë™ê¸°í™” ì‹œë®¬ë ˆì´ì…˜"""
        try:
            # Simulate user-specific sync delay
            await asyncio.sleep(0.1 + user_id * 0.02)
            
            # Process user items
            for item in items:
                await asyncio.sleep(0.01)
                item["synced"] = True
            
            return {"success": True, "user_id": user_id, "items_synced": len(items)}
            
        except Exception as e:
            return {"success": False, "user_id": user_id, "error": str(e)}

# Main execution
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ë°ì´í„° ë™ê¸°í™” í…ŒìŠ¤íŠ¸")
    parser.add_argument("--scenario", default="full", 
                       choices=["full", "conflict_resolution", "performance", "basic"],
                       help="í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒ")
    
    args = parser.parse_args()
    
    async def main():
        tester = DataSyncTest(scenario=args.scenario)
        passed, failed = await tester.run_sync_tests()
        
        # Save test results
        result_file = f"data_sync_test_results_{args.scenario}.json"
        with open(result_file, "w", encoding="utf-8") as f:
            json.dump({
                "scenario": args.scenario,
                "summary": {
                    "passed": passed,
                    "failed": failed,
                    "total": passed + failed,
                    "success_rate": passed / (passed + failed) * 100 if (passed + failed) > 0 else 0,
                    "execution_time": time.time() - tester.start_time
                },
                "details": tester.test_results
            }, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ {result_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        return passed == len(tester.test_results)
    
    success = asyncio.run(main())
    exit(0 if success else 1)