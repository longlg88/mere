#!/usr/bin/env python3
"""
ì‹œë§¨í‹± ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
Day 12: Search & Analytics Testing
"""

import asyncio
import sys
import os
import json
import time
from typing import List, Dict, Any
from pathlib import Path

# Add the backend directory to Python path
sys.path.append(str(Path(__file__).parent.parent.parent / "backend"))

from embedding_service import embedding_service, semantic_search_service
from search_api import *

class SemanticSearchTest:
    def __init__(self):
        self.test_results = []
        self.start_time = time.time()
    
    async def run_all_tests(self):
        """ëª¨ë“  ì‹œë§¨í‹± ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸ” ì‹œë§¨í‹± ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 60)
        
        test_scenarios = [
            self.test_embedding_generation,
            self.test_semantic_similarity,
            self.test_document_indexing,
            self.test_semantic_search,
            self.test_batch_operations,
            self.test_hybrid_search_logic,
            self.test_search_performance,
            self.test_multilingual_support
        ]
        
        passed = 0
        failed = 0
        
        for test_func in test_scenarios:
            try:
                result = await test_func()
                if result:
                    passed += 1
                    print(f"âœ… {test_func.__name__}: PASS")
                else:
                    failed += 1
                    print(f"âŒ {test_func.__name__}: FAIL")
                    
                self.test_results.append({
                    "test": test_func.__name__,
                    "status": "PASS" if result else "FAIL",
                    "timestamp": time.time() - self.start_time
                })
                
            except Exception as e:
                failed += 1
                print(f"âŒ {test_func.__name__}: ERROR - {e}")
                self.test_results.append({
                    "test": test_func.__name__,
                    "status": "ERROR",
                    "error": str(e),
                    "timestamp": time.time() - self.start_time
                })
        
        # Summary
        print("\n" + "=" * 60)
        print(f"ğŸ¯ ì‹œë§¨í‹± ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print(f"   í†µê³¼: {passed}")
        print(f"   ì‹¤íŒ¨: {failed}")
        print(f"   ì´ í…ŒìŠ¤íŠ¸: {passed + failed}")
        print(f"   ì„±ê³µë¥ : {(passed / (passed + failed) * 100):.1f}%")
        print(f"   ì‹¤í–‰ ì‹œê°„: {time.time() - self.start_time:.2f}ì´ˆ")
        
        return passed, failed
    
    async def test_embedding_generation(self) -> bool:
        """ì„ë² ë”© ìƒì„± í…ŒìŠ¤íŠ¸"""
        print("\nğŸ”¢ í…ŒìŠ¤íŠ¸: ì„ë² ë”© ìƒì„±")
        
        test_texts = [
            "ì˜¤ëŠ˜ íšŒì˜ ì¼ì •ì„ í™•ì¸í•´ì¤˜",
            "í”„ë¡œì íŠ¸ ê´€ë ¨ ë©”ëª¨ë¥¼ ì°¾ì•„ì¤˜",
            "í• ì¼ ëª©ë¡ì—ì„œ ì¤‘ìš”í•œ ê²ƒë“¤ì„ ë³´ì—¬ì¤˜",
            "ì§€ë‚œì£¼ ì‘ì„±í•œ ë¬¸ì„œë“¤ì´ ì–´ë””ìˆì§€?",
            "Meeting schedule for today"
        ]
        
        success_count = 0
        
        for text in test_texts:
            try:
                # Test individual embedding
                embedding = await embedding_service.get_embedding(text)
                
                if embedding and len(embedding) > 0:
                    dimension = len(embedding)
                    print(f"   âœ… '{text[:30]}...' -> {dimension}D ë²¡í„°")
                    success_count += 1
                    
                    # Verify embedding properties
                    if isinstance(embedding, list) and all(isinstance(x, float) for x in embedding):
                        print(f"      ë²¡í„° íƒ€ì…: ì˜¬ë°”ë¦„, ì°¨ì›: {dimension}")
                    else:
                        print(f"      âŒ ë²¡í„° íƒ€ì… ì˜¤ë¥˜")
                        return False
                else:
                    print(f"   âŒ '{text}' -> ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
                    
            except Exception as e:
                print(f"   âŒ '{text}' -> ì˜¤ë¥˜: {e}")
        
        success_rate = success_count / len(test_texts)
        print(f"   ğŸ“Š ì„ë² ë”© ìƒì„± ì„±ê³µë¥ : {success_rate * 100:.1f}% ({success_count}/{len(test_texts)})")
        
        return success_rate >= 0.8  # 80% ì´ìƒ ì„±ê³µë¥  ìš”êµ¬
    
    async def test_semantic_similarity(self) -> bool:
        """ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        print("\nğŸ“ í…ŒìŠ¤íŠ¸: ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚°")
        
        # Test cases with expected similarity relationships
        test_cases = [
            {
                "text1": "íšŒì˜ ì¼ì •ì„ í™•ì¸í•´ì¤˜",
                "text2": "ë¯¸íŒ… ìŠ¤ì¼€ì¤„ì„ ë³´ì—¬ì¤˜",
                "expected": "high",  # Should be highly similar
                "description": "í•œêµ­ì–´ ë™ì˜ì–´"
            },
            {
                "text1": "í”„ë¡œì íŠ¸ ë¬¸ì„œ ì‘ì„±",
                "text2": "í”„ë¡œì íŠ¸ ë³´ê³ ì„œ ì‘ì„±",
                "expected": "high",
                "description": "ê´€ë ¨ëœ ì‘ì—…"
            },
            {
                "text1": "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë‹¤",
                "text2": "í• ì¼ ëª©ë¡ í™•ì¸",
                "expected": "low",  # Should be low similarity
                "description": "ê´€ë ¨ ì—†ëŠ” ë‚´ìš©"
            },
            {
                "text1": "Create a memo",
                "text2": "ë©”ëª¨ë¥¼ ì‘ì„±í•´ì¤˜",
                "expected": "high",
                "description": "ë‹¤êµ­ì–´ ë™ì¼ ì˜ë¯¸"
            }
        ]
        
        similarity_tests_passed = 0
        
        for case in test_cases:
            try:
                # Get embeddings
                emb1 = await embedding_service.get_embedding(case["text1"])
                emb2 = await embedding_service.get_embedding(case["text2"])
                
                if emb1 and emb2:
                    similarity = embedding_service.cosine_similarity(emb1, emb2)
                    
                    # Check if similarity meets expectations
                    if case["expected"] == "high" and similarity > 0.7:
                        similarity_tests_passed += 1
                        print(f"   âœ… {case['description']}: {similarity:.3f} (ë†’ì€ ìœ ì‚¬ë„)")
                    elif case["expected"] == "low" and similarity < 0.5:
                        similarity_tests_passed += 1
                        print(f"   âœ… {case['description']}: {similarity:.3f} (ë‚®ì€ ìœ ì‚¬ë„)")
                    else:
                        print(f"   âŒ {case['description']}: {similarity:.3f} (ì˜ˆìƒê³¼ ë‹¤ë¦„)")
                else:
                    print(f"   âŒ {case['description']}: ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
                    
            except Exception as e:
                print(f"   âŒ {case['description']}: ì˜¤ë¥˜ - {e}")
        
        success_rate = similarity_tests_passed / len(test_cases)
        print(f"   ğŸ“Š ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸ ì„±ê³µë¥ : {success_rate * 100:.1f}% ({similarity_tests_passed}/{len(test_cases)})")
        
        return success_rate >= 0.75
    
    async def test_document_indexing(self) -> bool:
        """ë¬¸ì„œ ì¸ë±ì‹± í…ŒìŠ¤íŠ¸"""
        print("\nğŸ“š í…ŒìŠ¤íŠ¸: ë¬¸ì„œ ì¸ë±ì‹±")
        
        test_documents = [
            {"id": "doc_1", "content": "í”„ë¡œì íŠ¸ í‚¥ì˜¤í”„ ë¯¸íŒ…ì´ ë‚´ì¼ ì˜¤ì „ 10ì‹œì— ìˆìŠµë‹ˆë‹¤", "metadata": {"type": "memo", "category": "íšŒì˜"}},
            {"id": "doc_2", "content": "ì›”ê°„ ë³´ê³ ì„œ ì‘ì„± ì™„ë£Œí•´ì•¼ í•¨", "metadata": {"type": "todo", "priority": "high"}},
            {"id": "doc_3", "content": "íŒ€ ë¹Œë”© ì´ë²¤íŠ¸ ê³„íší•˜ê¸°", "metadata": {"type": "todo", "category": "ê¸°íš"}},
            {"id": "doc_4", "content": "ê¸°ìˆ  ë¬¸ì„œ ì—…ë°ì´íŠ¸ ë° ë°°í¬", "metadata": {"type": "memo", "category": "ê°œë°œ"}},
            {"id": "doc_5", "content": "ê³ ê° ë¯¸íŒ… í”¼ë“œë°± ì •ë¦¬", "metadata": {"type": "memo", "category": "íšŒì˜"}}
        ]
        
        indexed_count = 0
        
        for doc in test_documents:
            try:
                success = await semantic_search_service.index_document(
                    doc["id"], 
                    doc["content"], 
                    doc["metadata"]
                )
                
                if success:
                    indexed_count += 1
                    print(f"   âœ… ë¬¸ì„œ ì¸ë±ì‹± ì„±ê³µ: {doc['id']}")
                else:
                    print(f"   âŒ ë¬¸ì„œ ì¸ë±ì‹± ì‹¤íŒ¨: {doc['id']}")
                    
            except Exception as e:
                print(f"   âŒ ë¬¸ì„œ ì¸ë±ì‹± ì˜¤ë¥˜: {doc['id']} - {e}")
        
        # Check index stats
        stats = semantic_search_service.get_index_stats()
        print(f"   ğŸ“Š ì¸ë±ìŠ¤ í†µê³„: {stats['total_documents']}ê°œ ë¬¸ì„œ, {stats['embedding_dimension']}ì°¨ì›")
        
        success_rate = indexed_count / len(test_documents)
        print(f"   ğŸ“Š ì¸ë±ì‹± ì„±ê³µë¥ : {success_rate * 100:.1f}% ({indexed_count}/{len(test_documents)})")
        
        return success_rate >= 0.9
    
    async def test_semantic_search(self) -> bool:
        """ì‹œë§¨í‹± ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ” í…ŒìŠ¤íŠ¸: ì‹œë§¨í‹± ê²€ìƒ‰")
        
        search_queries = [
            {
                "query": "ë¯¸íŒ… ê´€ë ¨ ë‚´ìš©",
                "expected_docs": ["doc_1", "doc_5"],  # íšŒì˜ ê´€ë ¨ ë¬¸ì„œë“¤
                "min_results": 1
            },
            {
                "query": "ì‘ì—…í•´ì•¼ í•  ì¼ë“¤",
                "expected_docs": ["doc_2", "doc_3"],  # í• ì¼ ê´€ë ¨ ë¬¸ì„œë“¤
                "min_results": 1
            },
            {
                "query": "ë¬¸ì„œ ì‘ì„±",
                "expected_docs": ["doc_2", "doc_4"],  # ë¬¸ì„œ ê´€ë ¨ ì‘ì—…ë“¤
                "min_results": 1
            },
            {
                "query": "ì¡´ì¬í•˜ì§€ì•ŠëŠ”ë‚´ìš©ê²€ìƒ‰ì–´",
                "expected_docs": [],
                "min_results": 0
            }
        ]
        
        search_tests_passed = 0
        
        for query_data in search_queries:
            try:
                # Perform semantic search
                results = await semantic_search_service.search(
                    query_data["query"], 
                    top_k=10, 
                    min_similarity=0.1
                )
                
                found_docs = [r["doc_id"] for r in results]
                expected_found = any(doc_id in found_docs for doc_id in query_data["expected_docs"]) if query_data["expected_docs"] else True
                
                if len(results) >= query_data["min_results"] and expected_found:
                    search_tests_passed += 1
                    print(f"   âœ… ê²€ìƒ‰ '{query_data['query']}': {len(results)}ê°œ ê²°ê³¼")
                    for result in results[:3]:  # Show top 3 results
                        print(f"      - {result['doc_id']}: {result['similarity']:.3f}")
                else:
                    print(f"   âŒ ê²€ìƒ‰ '{query_data['query']}': ì˜ˆìƒ ê²°ê³¼ì™€ ë‹¤ë¦„ ({len(results)}ê°œ ê²°ê³¼)")
                    
            except Exception as e:
                print(f"   âŒ ê²€ìƒ‰ ì˜¤ë¥˜: '{query_data['query']}' - {e}")
        
        success_rate = search_tests_passed / len(search_queries)
        print(f"   ğŸ“Š ê²€ìƒ‰ ì„±ê³µë¥ : {success_rate * 100:.1f}% ({search_tests_passed}/{len(search_queries)})")
        
        return success_rate >= 0.75
    
    async def test_batch_operations(self) -> bool:
        """ë°°ì¹˜ ì—°ì‚° í…ŒìŠ¤íŠ¸"""
        print("\nğŸ“¦ í…ŒìŠ¤íŠ¸: ë°°ì¹˜ ì—°ì‚°")
        
        batch_texts = [
            "ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ë¬¸ì„œ 1",
            "ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ë¬¸ì„œ 2", 
            "ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ë¬¸ì„œ 3",
            "ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ë¬¸ì„œ 4",
            "ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ë¬¸ì„œ 5"
        ]
        
        try:
            # Test batch embedding generation
            start_time = time.time()
            embeddings = await embedding_service.get_embeddings_batch(batch_texts)
            batch_time = time.time() - start_time
            
            if len(embeddings) == len(batch_texts) and all(emb is not None for emb in embeddings):
                print(f"   âœ… ë°°ì¹˜ ì„ë² ë”©: {len(embeddings)}ê°œ ìƒì„±, {batch_time:.3f}ì´ˆ")
                
                # Test individual vs batch performance
                start_time = time.time()
                individual_embeddings = []
                for text in batch_texts:
                    emb = await embedding_service.get_embedding(text)
                    individual_embeddings.append(emb)
                individual_time = time.time() - start_time
                
                speedup = individual_time / batch_time if batch_time > 0 else 1.0
                print(f"   ğŸ“Š ì„±ëŠ¥ ë¹„êµ: ê°œë³„ {individual_time:.3f}ì´ˆ vs ë°°ì¹˜ {batch_time:.3f}ì´ˆ (ë°°ì†: {speedup:.1f}x)")
                
                return speedup >= 1.0  # Batch should be at least as fast
            else:
                print(f"   âŒ ë°°ì¹˜ ì„ë² ë”© ì‹¤íŒ¨: {len(embeddings)}/{len(batch_texts)}")
                return False
                
        except Exception as e:
            print(f"   âŒ ë°°ì¹˜ ì—°ì‚° ì˜¤ë¥˜: {e}")
            return False
    
    async def test_hybrid_search_logic(self) -> bool:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë¡œì§ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ”€ í…ŒìŠ¤íŠ¸: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë¡œì§")
        
        try:
            # Mock keyword search results
            keyword_results = [
                {"doc_id": "doc_1", "content": "í‚¤ì›Œë“œ ë§¤ì¹˜ ë¬¸ì„œ", "keyword_score": 0.8},
                {"doc_id": "doc_2", "content": "ë¶€ë¶„ í‚¤ì›Œë“œ ë§¤ì¹˜", "keyword_score": 0.5}
            ]
            
            # Test hybrid search
            query = "ë¯¸íŒ… ì¼ì •"
            hybrid_results = await semantic_search_service.hybrid_search(
                query, 
                keyword_results, 
                semantic_weight=0.7, 
                top_k=10
            )
            
            if len(hybrid_results) > 0:
                print(f"   âœ… í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: {len(hybrid_results)}ê°œ ê²°ê³¼")
                
                # Check if results have both scores
                for result in hybrid_results[:3]:
                    has_keyword = "keyword_score" in result and result["keyword_score"] is not None
                    has_semantic = "semantic_score" in result and result["semantic_score"] is not None
                    has_final = "final_score" in result and result["final_score"] is not None
                    
                    if has_keyword and has_semantic and has_final:
                        print(f"      âœ… {result.get('doc_id', 'unknown')}: í‚¤ì›Œë“œ={result['keyword_score']:.3f}, ì‹œë§¨í‹±={result['semantic_score']:.3f}, ìµœì¢…={result['final_score']:.3f}")
                    else:
                        print(f"      âŒ ì ìˆ˜ ëˆ„ë½: {result.get('doc_id', 'unknown')}")
                        return False
                
                return True
            else:
                print(f"   âŒ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                return False
                
        except Exception as e:
            print(f"   âŒ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return False
    
    async def test_search_performance(self) -> bool:
        """ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print("\nâš¡ í…ŒìŠ¤íŠ¸: ê²€ìƒ‰ ì„±ëŠ¥")
        
        try:
            # Performance test query
            test_query = "í”„ë¡œì íŠ¸ ê´€ë ¨ ë¬¸ì„œë“¤"
            iterations = 10
            
            total_time = 0
            successful_searches = 0
            
            for i in range(iterations):
                start_time = time.time()
                results = await semantic_search_service.search(test_query, top_k=5)
                search_time = time.time() - start_time
                
                if results is not None:
                    successful_searches += 1
                    total_time += search_time
            
            if successful_searches > 0:
                avg_time = total_time / successful_searches
                qps = 1.0 / avg_time if avg_time > 0 else 0
                
                print(f"   ğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­:")
                print(f"      í‰ê·  ê²€ìƒ‰ ì‹œê°„: {avg_time * 1000:.1f}ms")
                print(f"      ì´ˆë‹¹ ì¿¼ë¦¬ ìˆ˜: {qps:.1f} QPS")
                print(f"      ì„±ê³µë¥ : {successful_searches}/{iterations}")
                
                # Performance criteria: under 500ms per search
                return avg_time < 0.5 and successful_searches >= iterations * 0.9
            else:
                print(f"   âŒ ëª¨ë“  ê²€ìƒ‰ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            print(f"   âŒ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
            return False
    
    async def test_multilingual_support(self) -> bool:
        """ë‹¤êµ­ì–´ ì§€ì› í…ŒìŠ¤íŠ¸"""
        print("\nğŸŒ í…ŒìŠ¤íŠ¸: ë‹¤êµ­ì–´ ì§€ì›")
        
        multilingual_texts = [
            {"text": "íšŒì˜ ì¼ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”", "lang": "Korean"},
            {"text": "Please check the meeting schedule", "lang": "English"},
            {"text": "ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„", "lang": "Japanese"},
            {"text": "è¯·æ£€æŸ¥ä¼šè®®æ—¥ç¨‹", "lang": "Chinese"}
        ]
        
        embeddings_generated = 0
        cross_language_similarities = []
        
        try:
            # Generate embeddings for all languages
            embeddings = {}
            for item in multilingual_texts:
                embedding = await embedding_service.get_embedding(item["text"])
                if embedding:
                    embeddings[item["lang"]] = embedding
                    embeddings_generated += 1
                    print(f"   âœ… {item['lang']} ì„ë² ë”© ìƒì„± ì„±ê³µ")
                else:
                    print(f"   âŒ {item['lang']} ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
            
            # Test cross-language semantic similarity
            if "Korean" in embeddings and "English" in embeddings:
                similarity = embedding_service.cosine_similarity(
                    embeddings["Korean"], 
                    embeddings["English"]
                )
                cross_language_similarities.append(similarity)
                print(f"   ğŸ“Š í•œêµ­ì–´-ì˜ì–´ ìœ ì‚¬ë„: {similarity:.3f}")
            
            success_rate = embeddings_generated / len(multilingual_texts)
            avg_similarity = sum(cross_language_similarities) / len(cross_language_similarities) if cross_language_similarities else 0
            
            print(f"   ğŸ“Š ë‹¤êµ­ì–´ ì§€ì› ì„±ê³µë¥ : {success_rate * 100:.1f}%")
            print(f"   ğŸ“Š êµì°¨ ì–¸ì–´ ìœ ì‚¬ë„: {avg_similarity:.3f}")
            
            return success_rate >= 0.75 and avg_similarity > 0.5
            
        except Exception as e:
            print(f"   âŒ ë‹¤êµ­ì–´ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
            return False


# Main execution
if __name__ == "__main__":
    async def main():
        tester = SemanticSearchTest()
        passed, failed = await tester.run_all_tests()
        
        # Save test results
        result_file = "semantic_search_test_results.json"
        with open(result_file, "w", encoding="utf-8") as f:
            json.dump({
                "summary": {
                    "passed": passed,
                    "failed": failed,
                    "total": passed + failed,
                    "success_rate": passed / (passed + failed) * 100 if (passed + failed) > 0 else 0,
                    "execution_time": time.time() - tester.start_time
                },
                "details": tester.test_results
            }, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ {result_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # Return success if all tests passed
        return passed == (passed + failed)
    
    success = asyncio.run(main())
    exit(0 if success else 1)